<!doctype html>
<html lang="en">

   
  <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŽ“</text></svg>"> -->
  <link rel="icon" type="image/png" href="/icon/icon.jpg">

  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Alegreya:wght@500&family=Alegreya+SC&family=Lora:wght@400&display=swap" rel="stylesheet">

    
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <link rel="stylesheet" href="/css/style.css">
  </head>

  <body>



<div class="row pt-1 m-1">
              

<div class="container" style="text-align:center;">



  <div class="row mb-2">
    <div class="col">
      <p class="full-title"> ADGaussian: Generalizable Gaussian Splatting for Autonomous Driving with Multi-modal Inputs </p>
    </div>
  </div>
  
  <!-- <div class="row mb-4">
    <div class="col">
			
					<img src=/media/papers/vector-heat-method/big_teaser.jpg class="img-fluid big-teaser-image drop-shadow" alt="big teaser image">
			
		</div>
  </div> -->
  
  <div class="row">
    <div class="col">
      <div class="d-flex justify-content-center flex-nowrap authors-list" style="overflow-x: auto; white-space: nowrap;">
        
          <div class="ml-2 mr-2">
          
            <a href="https://maggiesong7.github.io/" class="plain-link">Qi Song</a><a class="plain-wo-link"><sup>1</sup></a>
          
          </div>
        
          <div class="ml-2 mr-2">
          
            <a href="https://kevinlee09.github.io" class="plain-link">Chenghong Li</a><a class="plain-wo-link"><sup>1</sup></a>
        

          <div class="ml-2 mr-2">
          
            <a href="https://haotongl.github.io/" class="plain-link">Haotong Lin</a><a class="plain-wo-link"><sup>2</sup></a>
          
          </div>


          <div class="ml-2 mr-2">
          
            <a href="https://myweb.cuhk.edu.cn/ruihuang" class="plain-link">Rui Huang</a><a class="plain-wo-link"><sup>#1</sup></a>
          
          </div>

          <div class="ml-2 mr-2">
          
            <a href="https://pengsida.net/" class="plain-link">Sida Peng</a><a class="plain-wo-link"><sup>#2</sup></a>
          
          </div>
        
      </div>
    </div>
  </div>

  <div class="row">
    <div class="col schools-list">
      <p>1. SSE, CUHKSZ &nbsp; &nbsp; 2. Zhejiang University </p>
    </div>
  </div>

  <div class="row mb-2">
    <div class="col publication-status">
      Arxiv 
    </div>
  </div>
  <div class="row mb-3">
    <div class="col">
      
    </div>
  </div>
  <div class="row mb-3">
    <div class="col">
      
      <div class="d-flex justify-content-center flex-wrap">
     
        <div>
          <a href="/media/papers/EMS/EMS.pdf" class="btn-lg big-badge-button ml-2 mr-2 mb-2" role="button">pdf (12MB)</a>
        </div>

      </div>
    </div>
  </div>


  <!-- <div class="row mb-4">
    <div class="col">
			
					<img src=/media/research/ADGaussian/teaser.png style="max-height:620pt;" class="img-fluid big-teaser-image drop-shadow" alt="big teaser image">
			
		</div>
  </div> -->

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline width="90%" height="auto">
          <source src="/media/research/ADGaussian/teaser_demo.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body" style="
        display: flex;
        gap: 20px;
        align-items: stretch; /* å…³é”®å±žæ€§ */
      ">
        <!-- è§†é¢‘1 -->
        <div style="flex: 1; position: relative; padding-top: 56.25%;"> <!-- 16:9 æ¯”ä¾‹ -->
          <video autoplay muted loop playsinline style="
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
          ">
            <source src="/media/research/ADGaussian/teaser_demo.mp4" type="video/mp4">
          </video>
        </div>
        
        <!-- è§†é¢‘2 -->
        <div style="flex: 1; position: relative; padding-top: 56.25%;"> <!-- ç›¸åŒæ¯”ä¾‹ -->
          <video autoplay muted loop playsinline style="
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
          ">
            <source src="/media/research/ADGaussian/new_demo.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </section>

  <div class="row">
    <div class="col">
      <p class="abstract">
        We introduce ADGaussian, a generalizable Gaussian framework for street scene reconstruction. Our approach achieves superior performance in both visual and geometric reconstruction. The bottom row illustrates the results of viewpoint shifting, further demonstrating the robustness of our method under varying viewpoint changes.
      </p>
    </div>
  </div>

  <div class="row content-header">
    <div class="col pr-0">
    <p>Abstract</p>
    </div>
  </div>
  <div class="row mb-4">
    <div class="col">
      <p class="abstract">
        We present a novel approach, termed ADGaussian, for generalizable street scene reconstruction. 
        The proposed method enables high-quality rendering from single-view input. Unlike prior Gaussian 
        Splatting methods that primarily focus on geometry refinement, we emphasize the importance of 
        joint optimization of image and depth features for accurate Gaussian prediction. To this end, we first 
        incorporate sparse LiDAR depth as an additional input modality, formulating the Gaussian prediction 
        process as a joint learning framework of visual information and geometric clue. Furthermore, we propose 
        a multi-modal feature matching strategy coupled with a multi-scale Gaussian decoding model to enhance 
        the joint refinement of multi-modal features, thereby enabling efficient multi-modal Gaussian learning. 
        Extensive experiments on two large-scale autonomous driving datasets, Waymo and KITTI, demonstrate that 
        our ADGaussian achieves state-of-the-art performance and exhibits superior zero-shot generalization capabilities in novel-view shifting.
      </p>
    </div>
  </div>
  


  <div class="row content-header">
    <div class="col pr-0">
    <p>Overview</p>
    </div>
  </div>
  <br/>
      
  <div class="container" style="text-align:center;">
  
    <div class="row justify-content-center mb-1">
        
          <img src= /media/research/ADGaussian/ADGaussian_pipeline.png class="figure-img img-fluid selected-figure drop-shadow">
        
    </div>
    <div class="row justify-content-center">
        <p class="abstract"> Given monocular posed image with sparse depth as input, ADGaussian first extracts well-fused multi-modal features through Multi-modal Feature Matching, which contains a siamese-style encoder and a cross-attention decoder enhanced by Depth-guided positional embedding (DPE). Subsequently, the Gaussian Head and Geometry Head, augmented with Multi-scale Gaussian Decoding, are utilized to predict different Gaussian parameters. </p>
    </div>
    <br/>
  
  </div>  

  <div class="row content-header">
    <div class="col pr-0">
    <p>Comparison</p>
    </div>
  </div>
  <br/>

  <div class="container" style="text-align:center;">
  
    <div class="row justify-content-center mb-1">
        
          <img src= /media/research/ADGaussian/shift.png style="max-height:750pt;" class="figure-img img-fluid selected-figure drop-shadow">
        
    </div>
  
  </div>  

  <div class="container" style="text-align:center;">
  
    <div class="row justify-content-center mb-1">
        
          <img src= /media/research/ADGaussian/sota_k.png style="max-height:750pt;" class="figure-img img-fluid selected-figure drop-shadow">
        
    </div>
    <br/>
    <br/>
  
  </div>  

  <div class="row content-header">
    <div class="col pr-0">
    <p>Zero-shot large-view rendering video</p>
    </div>
  </div>
  <br/>
      
  <div class="container" style="text-align:center;">
    
    <div class="row justify-content-center">
        <p class="abstract"> The concept of novel-view shifting involves generating images from significantly varied perspectives compared to the original viewpoints present in the training data. 
          We can evaluate the robustness on large viewpoint changes by applying the leftward and rightward view shifting. </p>
    </div>
    
      <div class="container is-max-desktop">
        <div class="hero-body">
          <video id="teaser" autoplay muted loop playsinline width="90%" height="auto">
            <source src="/media/research/ADGaussian/demo1.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
  
  </div> 

  <div class="container" style="text-align:center;">
    
    <div class="row justify-content-center">
        <p class="abstract"> We can also achieve the zero-shot left2right camera rendering on the KITTI dataset. Moreover, we can use the ground truth right camera images provided in the KITTI dataset to evaluate the quantitative performance of view shifting. </p>
    </div>
    
      <div class="container is-max-desktop">
        <div class="hero-body">
          <video id="teaser" autoplay muted loop playsinline width="90%" height="auto">
            <source src="/media/research/ADGaussian/demo2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
    <br/>
  
  </div> 


  <!-- <div class="row content-header">
    <div class="col pr-0">
    <p>Zero-shot large-view rendering video</p>
    </div>
  </div>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline width="90%" height="auto">
          <source src="/media/research/ADGaussian/demo1.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline width="90%" height="auto">
          <source src="/media/research/ADGaussian/demo2.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </section> -->

  <!-- <div class="row content-header">
    <div class="col pr-0">
    <p>Reference</p>
    </div>
  </div>


  <div class="bibtex">
    <pre> <code class="bibtex-code">
      @article{li2023ems,
        title={EMS: 3D Eyebrow Modeling from Single-view Images},
        author={Li, Chenghong and Jin, Leyang and Zheng, Yujian and Yu, Yizhou and Han, Xiaoguang},
        journal={ACM Transactions on Graphics (TOG)},
        volume={42},
        number={6},
        pages={1--19},
        year={2023},
        publisher={ACM New York, NY, USA}
      }
    </code></pre>
  </div> -->
  


</div>

<div class="row">
  <div class="col">
    
  </div>
</div>


            </div>
          </div>
          <div class="col-xl-1"></div>
        </div>
    </div>

    
    
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
  </body>
    
  <footer>


<div class="row">
<div class="col-12">
<br>
<br>
<br>
<br>
</div>
</div>


</footer>


</html>
