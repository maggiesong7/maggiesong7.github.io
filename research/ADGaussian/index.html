<!doctype html>
<html lang="en">

   
  <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŽ“</text></svg>"> -->
  <link rel="icon" type="image/png" href="/icon/icon.jpg">

  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Alegreya:wght@500&family=Alegreya+SC&family=Lora:wght@400&display=swap" rel="stylesheet">

    
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <link rel="stylesheet" href="/css/style.css">
  </head>

  <body>



<div class="row pt-1 m-1">
              

<div class="container" style="text-align:center;">



  <div class="row mb-2">
    <div class="col">
      <p class="full-title"> ADGaussian: Generalizable Gaussian Splatting for Autonomous Driving with Multi-modal Inputs </p>
    </div>
  </div>
  
  <!-- <div class="row mb-4">
    <div class="col">
			
					<img src=/media/papers/vector-heat-method/big_teaser.jpg class="img-fluid big-teaser-image drop-shadow" alt="big teaser image">
			
		</div>
  </div> -->
  
  <div class="row">
    <div class="col">
      <div class="d-flex justify-content-center flex-wrap authors-list">
        
          <div class="ml-2 mr-2">
          
            <a href="https://maggiesong7.github.io/" class="plain-link">Qi Song</a><a class="plain-wo-link"><sup>1</sup></a>
          
          </div>
        
          <div class="ml-2 mr-2">
          
            <a href="https://kevinlee09.github.io" class="plain-link">Chenghong Li</a><a class="plain-wo-link"><sup>1</sup></a>
        

          <div class="ml-2 mr-2">
          
            <a href="https://haotongl.github.io/" class="plain-link">Haotong Lin</a><a class="plain-wo-link"><sup>2</sup></a>
          
          </div>


          <div class="ml-2 mr-2">
          
            <a href="https://myweb.cuhk.edu.cn/ruihuang" class="plain-link">Rui Huang</a><a class="plain-wo-link"><sup>#1</sup></a>
          
          </div>

          <div class="ml-2 mr-2">
          
            <a href="https://pengsida.net/" class="plain-link">Sida Peng</a><a class="plain-wo-link"><sup>#2</sup></a>
          
          </div>
        
      </div>
    </div>
  </div>

  <div class="row">
    <div class="col schools-list">
      <p>1. SSE, CUHKSZ &nbsp; &nbsp; 2. Zhejiang University </p>
    </div>
  </div>

  <div class="row mb-2">
    <div class="col publication-status">
      Arxiv 
    </div>
  </div>
  <div class="row mb-3">
    <div class="col">
      
    </div>
  </div>
  <div class="row mb-3">
    <div class="col">
      
      <div class="d-flex justify-content-center flex-wrap">
     
        <div>
          <a href="/media/papers/EMS/EMS.pdf" class="btn-lg big-badge-button ml-2 mr-2 mb-2" role="button">pdf (12MB)</a>
        </div>

      </div>
    </div>
  </div>

  <!-- <div class="embed-responsive embed-responsive-16by9">
    <iframe width="540" height="315" src="/media/research/ADGaussian/demo1.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
  <br/>
  <br/> -->

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline width="90%" height="auto">
          <source src="/media/research/ADGaussian/demo1.mp4"
                  type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered" style="font-size: 1rem;">
          Zero-shot View Shifting on the Waymo Dataset: ADGaussian gains better zero-shot view shifting performance.
        </h2>
      </div>
    </div>
  </section>


  <!-- <div class="row mb-4">
    <div class="col">
			
					<img src=media/research/ADGaussian/ADGaussian_teaser.png class="img-fluid big-teaser-image drop-shadow" alt="big teaser image">
			
		</div>
  </div> -->

  <!-- <div class="row">
    <div class="col">
      <p class="abstract">
        Nowadays, 3D heads can be easily digitalized with high-fidelity geometry and texture, like the setup used in FaceScape. In this work, we proposed EMS, a learning-based approach, which can further reconstruct 3D eyebrows from just the frontal-view image. (a) the input image. (b) the cropped eyebrow image from (a). (c) our reconstructed fiber-level 3D eyebrow model rendered with multiple views. (d) the cropped rendering of (e) for comparison with (b). (e) putting our result on the textured 3D head can further improve the realism of face digitalization.
      </p>
    </div>
  </div> -->

  <div class="row content-header">
    <div class="col pr-0">
    <p>Abstract</p>
    </div>
  </div>
  <div class="row mb-4">
    <div class="col">
      <p class="abstract">
        We present a novel approach, termed ADGaussian, for generalizable street scene reconstruction. 
        The proposed method enables high-quality rendering from single-view input. Unlike prior Gaussian 
        Splatting methods that primarily focus on geometry refinement, we emphasize the importance of 
        joint optimization of image and depth features for accurate Gaussian prediction. To this end, we first 
        incorporate sparse LiDAR depth as an additional input modality, formulating the Gaussian prediction 
        process as a joint learning framework of visual information and geometric clue. Furthermore, we propose 
        a multi-modal feature matching strategy coupled with a multi-scale Gaussian decoding model to enhance 
        the joint refinement of multi-modal features, thereby enabling efficient multi-modal Gaussian learning. 
        Extensive experiments on two large-scale autonomous driving datasets, Waymo and KITTI, demonstrate that 
        our ADGaussian achieves state-of-the-art performance and exhibits superior zero-shot generalization capabilities in novel-view shifting.
      </p>
    </div>
  </div>
  

  
  <!-- <div class="row">
    <div class="col-1"> </div>
    <div class="col">
			<div class="embed-responsive embed-responsive-16by9">
				<iframe width="560" height="315" src="https://www.youtube.com/embed/MNbM78xIriM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </div>
    </div>
    <div class="col-1"> </div>
  </div> -->
  


  <div class="row content-header">
    <div class="col pr-0">
    <p>Overview</p>
    </div>
  </div>
  <br/>
      
  <div class="container" style="text-align:center;">
  
    <div class="row justify-content-center mb-1">
        
          <img src= /media/research/ADGaussian/ADGaussian_pipeline.png class="figure-img img-fluid selected-figure drop-shadow">
        
    </div>
    <div class="row justify-content-center">
        <p class="abstract"> Given monocular posed image with sparse depth as input, ADGaussian first extracts well-fused multi-modal features through Multi-modal Feature Matching, which contains a siamese-style encoder and a cross-attention decoder enhanced by Depth-guided positional embedding (DPE). Subsequently, the Gaussian Head and Geometry Head, augmented with Multi-scale Gaussian Decoding, are utilized to predict different Gaussian parameters. </p>
    </div>
    <br/>
    <br/>
  
  </div>  

  <div class="row content-header">
    <div class="col pr-0">
    <p>Comparison</p>
    </div>
  </div>
  <br/>

  <div class="container" style="text-align:center;">
  
    <div class="row justify-content-center mb-1">
        
          <img src= /media/research/ADGaussian/sota_k.jpg style="max-height:750pt;" class="paper-image img-fluid selected-figure drop-shadow">
        
    </div>
    <br/>
    <br/>
  
  </div>  

  <div class="container" style="text-align:center;">
  
    <div class="row justify-content-center mb-1">
        
          <img src= /media/research/ADGaussian/sota_w.jpg style="max-height:750pt;" class="paper-image img-fluid selected-figure drop-shadow">
        
    </div>
    <br/>
    <br/>
  
  </div>  

  <div class="row content-header">
    <div class="col pr-0">
    <p>Shifting Results</p>
    </div>
  </div>
  <br/>

  <div class="container" style="text-align:center;">
  
    <div class="row justify-content-center mb-1">
        
          <img src= /media/research/ADGaussian/shift.jpg style="max-height:400pt;" class="paper-image img-fluid selected-figure drop-shadow">
        
    </div>
    <br/>
    <br/>
  
  </div>  


  <div class="row content-header">
    <div class="col pr-0">
    <p>Zero-shot Right-camera Rendering on the KITTI Dataset</p>
    </div>
  </div>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline width="90%" height="auto">
          <source src="/media/research/ADGaussian/demo2.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </section>


  <div class="row content-header">
    <div class="col pr-0">
    <p>Reference</p>
    </div>
  </div>


  <div class="bibtex">
    <pre> <code class="bibtex-code">
      @article{li2023ems,
        title={EMS: 3D Eyebrow Modeling from Single-view Images},
        author={Li, Chenghong and Jin, Leyang and Zheng, Yujian and Yu, Yizhou and Han, Xiaoguang},
        journal={ACM Transactions on Graphics (TOG)},
        volume={42},
        number={6},
        pages={1--19},
        year={2023},
        publisher={ACM New York, NY, USA}
      }
    </code></pre>
  </div>
  


</div>

<div class="row">
  <div class="col">
    
  </div>
</div>


            </div>
          </div>
          <div class="col-xl-1"></div>
        </div>
    </div>

    
    
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
  </body>
    
  <footer>


<div class="row">
<div class="col-12">
<br>
<br>
<br>
<br>
</div>
</div>


</footer>


</html>
